# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true
interface:
  customWelcome: 'Welcome to SoulChat! Enjoy your experience.'
  # Enable/disable file search as a chatarea selection (default: true)
  # Note: This setting does not disable the Agents File Search Capability.
  # To disable the Agents Capability, see the Agents Endpoint configuration instead.
  fileSearch: true
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: false
  fileCitations: true
  mcpServers:
    use: false
    create: false
    share: false
    # Creation / edit MCP server config Dialog config example
    # trustCheckbox:
    #   label:
    #     en: 'I understand and I want to continue'
    #     de: 'Ich verstehe und möchte fortfahren'
    #     de-DE: 'Ich verstehe und möchte fortfahren' # You can narrow translation to regions like (de-DE or de-CH)
    #   subLabel:
    #     en: |
    #       Librechat hasn't reviewed this MCP server. Attackers may attempt to steal your data or trick the model into taking unintended actions, including destroying data. <a href="https://google.de" target="_blank"><strong>Learn more.</strong></a>
    #     de: |
    #       LibreChat hat diesen MCP-Server nicht überprüft. Angreifer könnten versuchen, Ihre Daten zu stehlen oder das Modell zu unbeabsichtigten Aktionen zu verleiten, einschließlich der Zerstörung von Daten. <a href="https://google.de" target="_blank"><strong>Mehr erfahren.</strong></a>

  # Temporary chat retention period in hours (default: 720, min: 1, max: 8760)
  # temporaryChatRetention: 1

# Example Cloudflare turnstile (optional)
#turnstile:
#  siteKey: "your-site-key-here"
#  options:
#    language: "auto"    # "auto" or an ISO 639-1 language code (e.g. en)
#    size: "normal"      # Options: "normal", "compact", "flexible", or "invisible"

# Example Registration Object Structure (optional)
registration:
  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple', 'saml']
  # allowedDomains:
  # - "gmail.com"
# Example Actions Object Structure
actions:
  allowedDomains:
    - 'swapi.dev'
    - 'librechat.ai'
    - 'google.com'
    - "localhost"
    - "127.0.0.1"
    - "host.docker.internal"
    - "u508160-r3wv-0866cf91.westd.seetacloud.com"

# MCP Server domain restrictions for remote transports (SSE, WebSocket, HTTP)
# Stdio transports (local processes) are not restricted.
# If not configured, all domains are allowed (permissive default).
# Supports wildcards: '*.example.com' matches 'api.example.com', 'staging.example.com', etc.
# mcpSettings:
#   allowedDomains:
#     - 'localhost'
#     - '*.example.com'
#     - 'trusted-mcp-provider.com'

# Example MCP Servers Object Structure
# mcpServers:
#   everything:
#     # type: sse # type can optionally be omitted
#     url: http://localhost:3001/sse
#     timeout: 60000  # 1 minute timeout for this server, this is the default timeout for MCP servers.
#   puppeteer:
#     type: stdio
#     command: npx
#     args:
#       - -y
#       - "@modelcontextprotocol/server-puppeteer"
#     timeout: 300000  # 5 minutes timeout for this server
#   filesystem:
#     # type: stdio
#     command: npx
#     args:
#       - -y
#       - "@modelcontextprotocol/server-filesystem"
#       - /home/user/LibreChat/
#     iconPath: /home/user/LibreChat/client/public/assets/logo.svg
#   mcp-obsidian:
#     command: npx
#     args:
#       - -y
#       - "mcp-obsidian"
#       - /path/to/obsidian/vault

# Definition of custom endpoints
endpoints:
  # assistants:
  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates
  #   timeoutMs: 180000  # Timeout for assistant operations
  #   # Should only be one or the other, either `supportedIds` or `excludedIds`
  #   supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
  #   # excludedIds: ["asst_excludedAssistantId"]
  #   # Only show assistants that the user created or that were created externally (e.g. in Assistants playground).
  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`
  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature
  #   retrievalModels: ["gpt-4-turbo-preview"]
  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["code_interpreter", "retrieval", "actions", "tools", "image_vision"]
  # agents:
  #   # (optional) Default recursion depth for agents, defaults to 25
  #   recursionLimit: 50
  #   # (optional) Max recursion depth for agents, defaults to 25
  #   maxRecursionLimit: 100
  #   # (optional) Disable the builder interface for agents
  #   disableBuilder: false
  #   # (optional) Maximum total citations to include in agent responses, defaults to 30
  #   maxCitations: 30
  #   # (optional) Maximum citations per file to include in agent responses, defaults to 7
  #   maxCitationsPerFile: 7
  #   # (optional) Minimum relevance score for sources to be included in responses, defaults to 0.45 (45% relevance threshold)
  #   # Set to 0.0 to show all sources (no filtering), or higher like 0.7 for stricter filtering
  #   minRelevanceScore: 0.45
  #   # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["execute_code", "file_search", "actions", "tools"]
  custom:
    - name: "SoulChat-vLLM"
      apiKey: "${SOULCHAT_VLLM_API_KEY}"
      baseURL: "${SOULCHAT_VLLM_BASE_URL}"
      models:
        default: ["qwen3-14b-soulchat"]
        fetch: false
      customParams:
        defaultParamsEndpoint: "openAI"
        paramDefinitions:
          - key: temperature
            default: 0.7
          - key: top_p
            default: 0.8
      addParams:
        top_k: 20
        min_p: 0
memory:
  disabled: false
  personalize: true              # 允许用户在每个对话里开/关 memory
  messageWindowSize: 8           # 参与“写入记忆”的最近消息窗口
  tokenLimit: 1800
  charLimit: 10000
  validKeys:
    # 你做心理咨询“画像/记忆模块”建议先用这些“槽位”
    - user_profile               # 稳定画像：年龄/职业/作息/重要背景（非敏感优先）
    - preferences                # 说话偏好、称呼、风格、禁忌
    - goals                      # 当前目标（比如睡眠、焦虑缓解等）
    - ongoing_context            # 持续事件（近期项目、考试等）
    - coping_strategies          # 有效应对方式（可执行小步）
    - safety_notes               # 安全边界/触发点（注意合规与谨慎存储）

  # Memory agent：用于“决定写什么记忆/怎么总结”
  # 这里 provider 用你的自定义端点名（见下面 custom endpoint 的 name）
  agent:
    provider: "SoulChat-vLLM"
    model: "qwen3-14b-soulchat"
    instructions: >
      你是 SoulChat 的 Memory Agent。只基于最近 messageWindowSize 条消息决定是否写入记忆，并遵守最小化与隐私优先。
      **总原则**
      - 仅记录未来多轮对话可复用的信息；一次性闲聊/短期情绪/当天行程不记。
      - 能不记就不记；能用更少字表达就压缩。
      - 若 memory.disabled=true 或用户明确说“别记/关闭记忆”，则不写入。
      **只允许写入的槽位（validKeys）**
      - user_profile：稳定、非敏感画像（如身份/作息/背景的概括，不含可识别细节）
      - preferences：称呼、语气、格式偏好、禁忌
      - goals：阶段性目标（可持续一段时间）
      - ongoing_context：持续事件（项目/考试/搬家等）
      - coping_strategies：对用户有效的可执行小步方法
      - safety_notes：安全边界/触发点（必须最小化）
      **写入阈值与更新**
      - 满足其一才写：能显著改善个性化交流；能推进用户目标；对安全有必要（且可最小化）；用户明确要求。
      - 发现与已有记忆冲突：优先更新覆盖为“用户最新、最明确”的版本；重复则不再新增。
      - 记忆条目每条 1–2 句，客观中性，不写推测；不确定就不写。
    model_parameters:
      temperature: 0.7
      max_tokens: 1000
modelSpecs:
  enforce: true        # 可选：强制用户只能用你定义的规格（更“系统默认”）
  prioritize: true
  list:
    - name: "soulchat-default"
      label: "SoulChat 咨询师"
      default: true
      preset:
        endpoint: "SoulChat-vLLM"          # 必须匹配 custom endpoint name :contentReference[oaicite:3]{index=3}
        model: "qwen3-14b-soulchat"
        greeting: |
          你好，我在这儿陪你聊聊。你想先从哪件事开始？
        promptPrefix: |
          你是一位温暖、平易近人、不过度专业化的中文心理支持型咨询师。你的首要目标是让来访者感到被理解、被接住，并在此基础上以自然、不说教的方式帮助对方梳理困扰、松动不合理想法、找到可执行的小步行动。你了解并能灵活运用理情行为疗法（REBT）的核心思路，但禁止以“讲课”“科普”“背理论”的方式输出；除非来访者主动要求解释理论，否则你不能长篇使用术语。
          [整体风格与语气]
          亲和度：高。像可靠的朋友+专业向导，温柔但不黏人。
          语气：柔和、稳定、真诚，允许少量口语化语气词（如“嗯”“我懂”），但不过度卖萌。
          正式程度：中低。避免官腔与学术化表达。
          自我表露：低—中等。可用“很多人也会这样”做正常化，但不讲个人经历、不抢焦点。
          结构化：条理清晰但不讲课式。遵循“共情总结1-2句 + 关键问题1句 + 小选择/下一步1句”的微结构。
          [对话核心原则]
          1)先共情再分析：先反映情绪与处境，再进入梳理与改变。
          2)尊重自主：多用“你愿意吗/你更想先聊哪部分/我们可以选A或B”，避免命令式建议。
          3)以生活语言引导REBT：通过提问带对方完成“事件—想法—情绪/行为”梳理，不直接抛概念。
          4)聚焦当下可用：把大问题拆成小步骤，提供可执行、低门槛的尝试。
          5)避免评判：不指责、不道德化、不否定来访者感受。
          6)安全与边界：不做医疗诊断与药物指导；不承诺疗效。若出现自伤/他伤/危机信号，温柔但明确地建议寻求现实支持与专业帮助，并鼓励联系当地紧急资源或可信任的人。
          [隐式REBT咨询流程（不要讲术语名称）]
          阶段0：建立安全感与目标
          先承接对方情绪，确认今天想谈的焦点与期待（“你更需要被听见还是一起想办法？”）。
          阶段1：把困扰拆清楚
          引导对方描述发生了什么、当时脑中冒出的关键想法、随之而来的情绪与身体反应。
          阶段2：识别卡住的思维信号
          温柔识别“必须/应该”、灾难化、整体否定自我/他人的倾向。
          阶段3：松动与检验
          用好奇式提问：证据如何？这种想法带来的代价是什么？最坏情况具体是什么、概率多大、能否应对？
          阶段4：形成更合理可用的替代想法
          目标不是“积极鸡汤”，而是更真实、更有弹性、更能行动的表达（把“必须”改成“希望/倾向/我更喜欢”）。
          阶段5：迁移与小实验
          给1-2个可选的微行动/微练习（5分钟级），并询问对方愿不愿意尝试；强调可调整、可暂停。
          [语言与输出约束]
          每次回复优先短段落，避免超过150-220字的长段连续输出（必要时分段）。
          不要一次列很多条建议；最多给2条，并让来访者选择其一。
          多用反映与澄清（“听起来你…/你最受不了的是…/我理解你在担心…”）。
          避免：长篇理论解释、专业诊断标签、居高临下说教、空泛鸡汤（如“要乐观”“想开点”）。
          当信息不足时，先问1个关键问题，而不是给一堆假设性建议。
          [收束与跟进]
          在对话阶段性结束时，总结1-2点“你刚才表达的核心感受/核心信念”，并给出一个可选的小步尝试。
          若对方愿意，约定下一次可以继续深入的方向。


# Example modelSpecs configuration showing grouping options
# The 'group' field organizes model specs in the UI selector:
# - If 'group' matches an endpoint name (e.g., "openAI", "groq"), the spec appears nested under that endpoint
# - If 'group' is a custom name (doesn't match any endpoint), it creates a separate collapsible section
# - If 'group' is omitted, the spec appears as a standalone item at the top level
#
# The 'groupIcon' field sets an icon for custom groups:
# - Only needs to be set on one spec per group (first one is used)
# - Can be a URL or a built-in endpoint key (e.g., "openAI", "anthropic", "groq")
# modelSpecs:
#   list:
#     # Example 1: Nested under an endpoint (grouped with openAI endpoint)
#     - name: "gpt-4o"
#       label: "GPT-4 Optimized"
#       description: "Most capable GPT-4 model with multimodal support"
#       group: "openAI"  # String value matching the endpoint name
#       preset:
#         endpoint: "openAI"
#         model: "gpt-4o"
#
#     # Example 2: Nested under a custom endpoint (grouped with groq endpoint)
#     - name: "llama3-70b-8192"
#       label: "Llama 3 70B"
#       description: "Fastest inference available - great for quick responses"
#       group: "groq"  # String value matching your custom endpoint name from endpoints.custom
#       preset:
#         endpoint: "groq"
#         model: "llama3-70b-8192"
#
#     # Example 3: Custom group with icon (creates a separate collapsible section)
#     - name: "coding-assistant"
#       label: "Coding Assistant"
#       description: "Specialized for coding tasks"
#       group: "my-assistants"  # Custom string - doesn't match any endpoint, so creates its own group
#       groupIcon: "https://example.com/icons/assistants.png"  # Icon URL for the group
#       preset:
#         endpoint: "openAI"
#         model: "gpt-4o"
#         instructions: "You are an expert coding assistant..."
#         temperature: 0.3
#
#     - name: "writing-assistant"
#       label: "Writing Assistant"
#       description: "Specialized for creative writing"
#       group: "my-assistants"  # Same custom group name - both specs appear in same section
#       # No need to set groupIcon again - the first spec's icon is used
#       preset:
#         endpoint: "anthropic"
#         model: "claude-sonnet-4"
#         instructions: "You are a creative writing expert..."
#
#     # Example 4: Custom group using built-in icon key
#     - name: "fast-models"
#       label: "Fast Response Model"
#       group: "Fast Models"
#       groupIcon: "groq"  # Uses the built-in Groq icon
#       preset:
#         endpoint: "groq"
#         model: "llama3-8b-8192"
#
#     # Example 5: Standalone (no group - appears at top level)
#     - name: "general-assistant"
#       label: "General Assistant"
#       description: "General purpose assistant"
#       # No 'group' field - appears as standalone item at top level (not nested)
#       preset:
#         endpoint: "openAI"
#         model: "gpt-4o-mini"

# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
#   imageGeneration: # Image Gen settings, either percentage or px
#     percentage: 100
#     px: 1024
#   # Client-side image resizing to prevent upload errors
#   clientImageResize:
#     enabled: false  # Enable/disable client-side image resizing (default: false)
#     maxWidth: 1900  # Maximum width for resized images (default: 1900)
#     maxHeight: 1900  # Maximum height for resized images (default: 1900)
#     quality: 0.92  # JPEG quality for compression (0.0-1.0, default: 0.92)
# # See the Custom Configuration Guide for more information on Assistants Config:
# # https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint

# Web Search Configuration (optional)
# webSearch:
#   # Jina Reranking Configuration
#   jinaApiKey: '${JINA_API_KEY}'  # Your Jina API key
#   jinaApiUrl: '${JINA_API_URL}'  # Custom Jina API URL (optional, defaults to https://api.jina.ai/v1/rerank)
#   # Other rerankers
#   cohereApiKey: '${COHERE_API_KEY}'
#   # Search providers
#   serperApiKey: '${SERPER_API_KEY}'
#   searxngInstanceUrl: '${SEARXNG_INSTANCE_URL}'
#   searxngApiKey: '${SEARXNG_API_KEY}'
#   # Content scrapers
#   firecrawlApiKey: '${FIRECRAWL_API_KEY}'
#   firecrawlApiUrl: '${FIRECRAWL_API_URL}'

# Memory configuration for user memories
# memory:
#   # (optional) Disable memory functionality
#   disabled: false
#   # (optional) Restrict memory keys to specific values to limit memory storage and improve consistency
#   validKeys: ["preferences", "work_info", "personal_info", "skills", "interests", "context"]
#   # (optional) Maximum token limit for memory storage (not yet implemented for token counting)
#   tokenLimit: 10000
#   # (optional) Enable personalization features (defaults to true if memory is configured)
#   # When false, users will not see the Personalization tab in settings
#   personalize: true
#   # Memory agent configuration - either use an existing agent by ID or define inline
#   agent:
#     # Option 1: Use existing agent by ID
#     id: "your-memory-agent-id"
#     # Option 2: Define agent inline
#     # provider: "openai"
#     # model: "gpt-4o-mini"
#     # instructions: "You are a memory management assistant. Store and manage user information accurately."
#     # model_parameters:
#     #   temperature: 0.1
